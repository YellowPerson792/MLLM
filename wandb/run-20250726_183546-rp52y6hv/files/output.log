  0%|                                                                              | 0/4500 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.
  8%|█████▏                                                              | 341/4500 [02:49<34:28,  2.01it/s]Traceback (most recent call last):
{'loss': 1.533, 'grad_norm': 2.7492222785949707, 'learning_rate': 4.978888888888889e-05, 'epoch': 0.01}
{'loss': 0.5158, 'grad_norm': 2.990328788757324, 'learning_rate': 4.956666666666667e-05, 'epoch': 0.03}
{'loss': 0.5071, 'grad_norm': 2.7342662811279297, 'learning_rate': 4.934444444444445e-05, 'epoch': 0.04}
{'loss': 0.522, 'grad_norm': 3.690903663635254, 'learning_rate': 4.912222222222223e-05, 'epoch': 0.05}
{'loss': 0.4535, 'grad_norm': 3.3360118865966797, 'learning_rate': 4.89e-05, 'epoch': 0.07}
{'loss': 0.4805, 'grad_norm': 2.2412750720977783, 'learning_rate': 4.867777777777778e-05, 'epoch': 0.08}
{'loss': 0.424, 'grad_norm': 2.493443250656128, 'learning_rate': 4.845555555555556e-05, 'epoch': 0.09}
{'loss': 0.5089, 'grad_norm': 2.4087507724761963, 'learning_rate': 4.823333333333334e-05, 'epoch': 0.11}
{'loss': 0.4564, 'grad_norm': 2.032639980316162, 'learning_rate': 4.8011111111111114e-05, 'epoch': 0.12}
{'loss': 0.4689, 'grad_norm': 1.7066689729690552, 'learning_rate': 4.778888888888889e-05, 'epoch': 0.13}
{'loss': 0.4101, 'grad_norm': 1.6413987874984741, 'learning_rate': 4.756666666666667e-05, 'epoch': 0.15}
{'loss': 0.4671, 'grad_norm': 1.5999950170516968, 'learning_rate': 4.734444444444445e-05, 'epoch': 0.16}
{'loss': 0.4435, 'grad_norm': 1.344480037689209, 'learning_rate': 4.7122222222222225e-05, 'epoch': 0.17}
{'loss': 0.4645, 'grad_norm': 1.8908761739730835, 'learning_rate': 4.69e-05, 'epoch': 0.19}
{'loss': 0.4445, 'grad_norm': 1.469231128692627, 'learning_rate': 4.6677777777777785e-05, 'epoch': 0.2}
{'loss': 0.4626, 'grad_norm': 1.5089430809020996, 'learning_rate': 4.645555555555556e-05, 'epoch': 0.21}
{'loss': 0.4301, 'grad_norm': 1.1499536037445068, 'learning_rate': 4.623333333333334e-05, 'epoch': 0.23}
  File "/root/autodl-tmp/MLLM/ImageCaption/train_vit-gpt2.py", line 148, in <module>
    trainer.train()
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/trainer.py", line 2240, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/trainer.py", line 2509, in _inner_training_loop
    batch_samples, num_items_in_batch = self.get_batch_samples(epoch_iterator, num_batches, args.device)
                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/trainer.py", line 5263, in get_batch_samples
    batch_samples.append(next(epoch_iterator))
                         ^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/accelerate/data_loader.py", line 577, in __iter__
    next_batch = next(dataloader_iter)
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 789, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 50, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py", line 2781, in __getitems__
    batch = self.__getitem__(keys)
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/datasets/formatting/formatting.py", line 410, in __call__
    return self.format_batch(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/datasets/formatting/formatting.py", line 466, in format_batch
    batch = self.python_arrow_extractor().extract_batch(pa_table)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/datasets/formatting/formatting.py", line 149, in extract_batch
    return pa_table.to_pydict()
           ^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
