/root/autodl-tmp/MLLM/ImageCaption/hf_style_trainer.py:178: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.fp16)
Training:   0%|                                                            | 0/9000 [00:00<?, ?it/s]/root/autodl-tmp/MLLM/ImageCaption/hf_style_trainer.py:240: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp, dtype=torch.bfloat16 if args.bf16 else torch.float16):
/root/miniconda3/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:557: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).
  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/root/miniconda3/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.
  warnings.warn(DEPRECATION_WARNING, FutureWarning)
Training:   1%| | 128/9000 [02:03<2:29:57,  1.01s/it, ep=0.04/3, step=128, loss=1.8047, lr=1.97e-04]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
[Batch    64] [Opt    8] [Ep  0.021] | Loss:  2.6016 | GradNorm:  50.712 | LR: 1.99e-04
[Batch   128] [Opt   16] [Ep  0.043] | Loss:  1.8047 | GradNorm:  36.037 | LR: 1.97e-04
Training:   6%| | 512/9000 [08:58<2:21:52,  1.00s/it, ep=0.17/3, step=512, loss=2.7812, lr=1.89e-04]/root/miniconda3/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in  - will assume that the vocabulary was not modified.
  warnings.warn(                                                                                    
[Batch   128] [EVAL] | Loss:  2.7485 | accuracy: 0.0625 | rouge2_fmeasure: 0.0000 | bleu1: 0.0625 | bleu4: 0.0625
[Batch   192] [Opt   24] [Ep  0.064] | Loss:  2.6797 | GradNorm:  48.583 | LR: 1.96e-04
[Batch   256] [Opt   32] [Ep  0.085] | Loss:  2.8359 | GradNorm:  49.266 | LR: 1.94e-04
[Batch   256] [EVAL] | Loss:  2.2913 | accuracy: 0.0625 | rouge2_fmeasure: 0.0000 | bleu1: 0.0625 | bleu4: 0.0625
[Batch   320] [Opt   40] [Ep  0.107] | Loss:  2.8750 | GradNorm:  43.400 | LR: 1.93e-04
[Batch   384] [Opt   48] [Ep  0.128] | Loss:  2.4961 | GradNorm:  35.660 | LR: 1.91e-04
[Batch   384] [EVAL] | Loss:  2.4295 | accuracy: 0.1875 | rouge2_fmeasure: 0.0000 | bleu1: 0.1875 | bleu4: 0.1875
[Batch   448] [Opt   56] [Ep  0.149] | Loss:  2.2656 | GradNorm:  55.499 | LR: 1.90e-04
[Batch   512] [Opt   64] [Ep  0.171] | Loss:  2.7812 | GradNorm:  58.466 | LR: 1.89e-04
[Batch   512] [EVAL] | Loss:  2.2769 | accuracy: 0.1250 | rouge2_fmeasure: 0.0000 | bleu1: 0.1250 | bleu4: 0.1250
[Batch   512] [SAVE] | 保存检查点到 checkpoint-512
Training:  11%| | 965/9000 [16:45<2:07:16,  1.05it/s, ep=0.32/3, step=965, loss=2.5156, lr=1.79e-04]Traceback (most recent call last):
[Batch   576] [Opt   72] [Ep  0.192] | Loss:  2.4453 | GradNorm:  35.361 | LR: 1.87e-04
[Batch   640] [Opt   80] [Ep  0.213] | Loss:  2.1680 | GradNorm:  43.123 | LR: 1.86e-04
  File "/root/autodl-tmp/MLLM/ImageCaption/train_jpeglm-gpt2_cls.py", line 353, in <module>         
[Batch   640] [EVAL] | Loss:  2.5222 | accuracy: 0.1875 | rouge2_fmeasure: 0.0000 | bleu1: 0.1875 | bleu4: 0.1875
[Batch   704] [Opt   88] [Ep  0.235] | Loss:  2.5625 | GradNorm:  36.720 | LR: 1.84e-04
[Batch   768] [Opt   96] [Ep  0.256] | Loss:  2.3438 | GradNorm:  52.027 | LR: 1.83e-04
[Batch   768] [EVAL] | Loss:  2.2337 | accuracy: 0.1875 | rouge2_fmeasure: 0.0000 | bleu1: 0.1875 | bleu4: 0.1875
[Batch   832] [Opt  104] [Ep  0.277] | Loss:  2.4531 | GradNorm:  51.510 | LR: 1.82e-04
[Batch   896] [Opt  112] [Ep  0.299] | Loss:  2.2891 | GradNorm:  45.694 | LR: 1.80e-04
[Batch   896] [EVAL] | Loss:  2.2941 | accuracy: 0.1875 | rouge2_fmeasure: 0.0000 | bleu1: 0.1875 | bleu4: 0.1875
[Batch   960] [Opt  120] [Ep  0.320] | Loss:  2.1719 | GradNorm:  53.238 | LR: 1.79e-04
    trainer.train()
  File "/root/autodl-tmp/MLLM/ImageCaption/hf_style_trainer.py", line 244, in train
    scaler.scale(loss).backward()
  File "/root/miniconda3/lib/python3.12/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/root/miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/root/miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
