{
  "os": "Linux-5.15.0-78-generic-x86_64-with-glibc2.35",
  "python": "CPython 3.12.3",
  "startedAt": "2025-07-30T11:05:45.712319Z",
  "args": [
    "--train_batch_size",
    "1",
    "--eval_batch_size",
    "1",
    "--eval_strategy",
    "steps",
    "--eval_steps",
    "512",
    "--logging_steps",
    "64",
    "--save_steps",
    "512",
    "--warmup_steps",
    "512",
    "--learning_rate",
    "5e-5",
    "--num_train_epochs",
    "3",
    "--save_total_limit",
    "1",
    "--lr_scheduler_type",
    "linear",
    "--gradient_accumulation_steps",
    "8",
    "--report_to",
    "wandb",
    "--bf16",
    "--max_length",
    "2048",
    "--image_size",
    "96"
  ],
  "program": "/root/autodl-tmp/MLLM/ImageCaption/train_jpeglm-gpt2.py",
  "codePath": "ImageCaption/train_jpeglm-gpt2.py",
  "git": {
    "remote": "https://github.com/YellowPerson792/MLLM.git",
    "commit": "7bb3cb0b523bd08cfd51fa48dc03ecc80e3d9af9"
  },
  "email": "yellow_person@outlook.com",
  "root": "/root/autodl-tmp/MLLM",
  "host": "autodl-container-94144787f5-2fa73ce0",
  "executable": "/root/miniconda3/bin/python",
  "codePathLocal": "ImageCaption/train_jpeglm-gpt2.py",
  "cpu_count": 64,
  "cpu_count_logical": 128,
  "gpu": "NVIDIA vGPU-32GB",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "32212254720",
      "used": "27607953408"
    }
  },
  "memory": {
    "total": "1081808056320"
  },
  "cpu": {
    "count": 64,
    "countLogical": 128
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA vGPU-32GB",
      "memoryTotal": "34351349760",
      "cudaCores": 10240,
      "architecture": "Ada"
    }
  ],
  "cudaVersion": "12.4"
}